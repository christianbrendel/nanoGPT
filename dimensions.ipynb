{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimensions (strange numbers taken on purpose)\n",
    "batch_size = 27\n",
    "c = 11\n",
    "\n",
    "# Model parameters (strange numbers taken on purpose)\n",
    "d_model = 64\n",
    "d_head = 17\n",
    "n_heads = 5\n",
    "d_inner = 123\n",
    "vocab_size = 23\n",
    "n_blocks = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 17])\n"
     ]
    }
   ],
   "source": [
    "# Attention Head\n",
    "\n",
    "attn_head = AttentionHead(d_model=d_model, d_head=d_head)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "o = attn_head(x)\n",
    "\n",
    "print(f\"{x.shape} -> {o.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Multi-Head Attention\n",
    "\n",
    "mha = MultiHeadAttention(d_model=d_model, n_heads=n_heads, d_head=d_head)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = mha(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Feed Forward\n",
    "\n",
    "ff = FeedForward(d_model=d_model, d_inner=d_inner)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = ff(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Basic Building Block\n",
    "\n",
    "b = Block(d_model=d_model, n_heads=n_heads, d_head=d_head, d_inner=d_inner)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = b(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11]) -> torch.Size([27, 11, 64]) -> torch.Size([27, 11, 23])\n"
     ]
    }
   ],
   "source": [
    "# Language Model\n",
    "\n",
    "lm = LanguageModel(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, n_blocks=n_blocks)\n",
    "\n",
    "idx = torch.randint(0, vocab_size, (batch_size, c))\n",
    "x_new, _ = lm(idx)\n",
    "\n",
    "print(f\"{idx.shape} -> {x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note on nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WEIGHTS OF THE TOKEN EMBEDDING TABLE ---\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.1978, -0.9415,  0.1220, -2.1716],\n",
      "        [ 0.5547, -0.8293, -1.8911,  0.1926],\n",
      "        [ 1.5990, -1.7100, -0.9501,  1.2014],\n",
      "        [-0.3939, -0.9876,  0.8104,  0.3245],\n",
      "        [-0.0311,  1.4183,  1.6611, -0.6586]], requires_grad=True)\n",
      "torch.Size([5, 4])\n",
      "\n",
      "\n",
      "--- WEIGHTS OF THE POSITION EMBEDDING TABLE ---\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.1639, -2.5262,  0.0626, -0.4400],\n",
      "        [-0.5536, -0.4538, -0.8721,  1.1158],\n",
      "        [ 0.3666, -0.1443,  1.7843, -0.2331],\n",
      "        [ 0.3175,  1.2170,  0.2160, -0.4171],\n",
      "        [-0.5369, -0.8636,  0.8445,  0.6123],\n",
      "        [-1.0339, -0.1021,  0.1612, -0.5991],\n",
      "        [ 0.6750,  1.4297, -1.3731,  0.8217]], requires_grad=True)\n",
      "torch.Size([7, 4])\n",
      "\n",
      "\n",
      "--- INPUT INDICES ---\n",
      "\n",
      "tensor([[3, 0, 0],\n",
      "        [1, 0, 1]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "--- TOKEN EMBEDDINGS ---\n",
      "\n",
      "tensor([[[-0.3939, -0.9876,  0.8104,  0.3245],\n",
      "         [-0.1978, -0.9415,  0.1220, -2.1716],\n",
      "         [-0.1978, -0.9415,  0.1220, -2.1716]],\n",
      "\n",
      "        [[ 0.5547, -0.8293, -1.8911,  0.1926],\n",
      "         [-0.1978, -0.9415,  0.1220, -2.1716],\n",
      "         [ 0.5547, -0.8293, -1.8911,  0.1926]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 3, 4])\n",
      "\n",
      "\n",
      "--- POSITION EMBEDDINGS ---\n",
      "\n",
      "tensor([0, 1, 2])\n",
      "tensor([[-0.1639, -2.5262,  0.0626, -0.4400],\n",
      "        [-0.5536, -0.4538, -0.8721,  1.1158],\n",
      "        [ 0.3666, -0.1443,  1.7843, -0.2331]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 4])\n",
      "\n",
      "\n",
      "--- ADDING TOKEN EMBEDDINGS AND POSITION EMBEDDINGS ---\n",
      "\n",
      "tensor([[[-0.5577, -3.5137,  0.8730, -0.1155],\n",
      "         [-0.7514, -1.3952, -0.7501, -1.0558],\n",
      "         [ 0.1688, -1.0858,  1.9063, -2.4047]],\n",
      "\n",
      "        [[ 0.3909, -3.3555, -1.8285, -0.2473],\n",
      "         [-0.7514, -1.3952, -0.7501, -1.0558],\n",
      "         [ 0.9214, -0.9736, -0.1067, -0.0404]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# model parameter\n",
    "vocab_size = 5\n",
    "block_size = 7\n",
    "d_model = 4\n",
    "\n",
    "# input parameters\n",
    "sequence_length = 3\n",
    "batch_size = 2\n",
    "\n",
    "# embedding tables\n",
    "token_embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "position_embedding_table = nn.Embedding(block_size, d_model)\n",
    "\n",
    "\n",
    "print(\"--- WEIGHTS OF THE TOKEN EMBEDDING TABLE ---\\n\")\n",
    "print(token_embedding_table.weight) # 5 different tokens, each one is 4-dimensional\n",
    "print(token_embedding_table.weight.shape)\n",
    "\n",
    "\n",
    "print(\"\\n\\n--- WEIGHTS OF THE POSITION EMBEDDING TABLE ---\\n\")\n",
    "print(position_embedding_table.weight) # 7 different positions, each one is 4-dimensional\n",
    "print(position_embedding_table.weight.shape)\n",
    "\n",
    "print(\"\\n\\n--- INPUT INDICES ---\\n\")\n",
    "idx = torch.randint(0, vocab_size, (batch_size, sequence_length)) # 3 random indices between 0 and 4\n",
    "print(idx)\n",
    "print(idx.shape)\n",
    "\n",
    "print(\"\\n\\n--- TOKEN EMBEDDINGS ---\\n\")\n",
    "token_embeddings = token_embedding_table(idx) # 2 sequences of 3 tokens, each one is 4-dimensional\n",
    "print(token_embeddings)\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "print(\"\\n\\n--- POSITION EMBEDDINGS ---\\n\")\n",
    "t = torch.arange(sequence_length) # 3 positions\n",
    "print(t)\n",
    "position_embeddings = position_embedding_table(t) # 3 positions, each one is 4-dimensional\n",
    "print(position_embeddings)\n",
    "print(position_embeddings.shape)\n",
    "\n",
    "print(\"\\n\\n--- ADDING TOKEN EMBEDDINGS AND POSITION EMBEDDINGS ---\\n\")\n",
    "print(token_embeddings + position_embeddings)\n",
    "print((token_embeddings + position_embeddings).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
