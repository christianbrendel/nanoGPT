{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimensions (strange numbers taken on purpose)\n",
    "batch_size = 27\n",
    "c = 11\n",
    "\n",
    "# Model parameters (strange numbers taken on purpose\n",
    "d_model = 64\n",
    "d_head = 17\n",
    "n_heads = 5\n",
    "d_inner = 123\n",
    "vocab_size = 23\n",
    "n_blocks = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 17])\n"
     ]
    }
   ],
   "source": [
    "# Attention Head\n",
    "\n",
    "attn_head = AttentionHead(d_model=d_model, d_head=d_head)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "o = attn_head(x)\n",
    "\n",
    "print(f\"{x.shape} -> {o.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Multi-Head Attention\n",
    "\n",
    "mha = MultiHeadAttention(d_model=d_model, n_heads=n_heads, d_head=d_head)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = mha(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Feed Forward\n",
    "\n",
    "ff = FeedForward(d_model=d_model, d_inner=d_inner)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = ff(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11, 64]) -> torch.Size([27, 11, 64])\n"
     ]
    }
   ],
   "source": [
    "# Basic Building Block\n",
    "\n",
    "b = Block(d_model=d_model, n_heads=n_heads, d_head=d_head, d_inner=d_inner)\n",
    "\n",
    "x = torch.randn(batch_size, c, d_model)\n",
    "x_new = b(x)\n",
    "\n",
    "print(f\"{x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 11]) -> torch.Size([27, 11, 64]) -> torch.Size([27, 11, 23])\n"
     ]
    }
   ],
   "source": [
    "# Language Model\n",
    "\n",
    "lm = LanguageModel(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, n_blocks=n_blocks)\n",
    "\n",
    "idx = torch.randint(0, vocab_size, (batch_size, c))\n",
    "x_new, _ = lm(idx)\n",
    "\n",
    "print(f\"{idx.shape} -> {x.shape} -> {x_new.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note on nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WEIGHTS OF THE TOKEN EMBEDDING TABLE ---\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 1.0325,  0.7264,  1.0161,  2.0160],\n",
      "        [ 0.3157,  0.0622, -1.7561, -0.1970],\n",
      "        [-0.9901, -0.7923,  1.2296, -0.0728],\n",
      "        [ 0.5098, -0.2969,  0.9309, -1.7869],\n",
      "        [ 1.6245,  0.9987,  0.5837,  0.7846]], requires_grad=True)\n",
      "torch.Size([5, 4])\n",
      "\n",
      "\n",
      "--- WEIGHTS OF THE POSITION EMBEDDING TABLE ---\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.8765, -0.1246,  0.4092, -1.0750],\n",
      "        [ 1.7209,  0.4917,  1.2667, -0.1124],\n",
      "        [ 1.6285, -1.5780,  1.2353,  0.1783],\n",
      "        [ 0.5356,  0.7281,  0.6711, -0.0864],\n",
      "        [-1.4852, -0.0774,  1.0756,  0.0436],\n",
      "        [-0.2980,  1.7133, -0.7907, -1.8390],\n",
      "        [ 0.3887,  0.2321, -0.9094,  0.0071]], requires_grad=True)\n",
      "torch.Size([7, 4])\n",
      "\n",
      "\n",
      "--- INPUT INDICES ---\n",
      "\n",
      "tensor([[2, 2, 3],\n",
      "        [3, 1, 2]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "--- TOKEN EMBEDDINGS ---\n",
      "\n",
      "tensor([[[-0.9901, -0.7923,  1.2296, -0.0728],\n",
      "         [-0.9901, -0.7923,  1.2296, -0.0728],\n",
      "         [ 0.5098, -0.2969,  0.9309, -1.7869]],\n",
      "\n",
      "        [[ 0.5098, -0.2969,  0.9309, -1.7869],\n",
      "         [ 0.3157,  0.0622, -1.7561, -0.1970],\n",
      "         [-0.9901, -0.7923,  1.2296, -0.0728]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 3, 4])\n",
      "\n",
      "\n",
      "--- POSITION EMBEDDINGS ---\n",
      "\n",
      "tensor([0, 1, 2])\n",
      "tensor([[-0.8765, -0.1246,  0.4092, -1.0750],\n",
      "        [ 1.7209,  0.4917,  1.2667, -0.1124],\n",
      "        [ 1.6285, -1.5780,  1.2353,  0.1783]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 4])\n",
      "\n",
      "\n",
      "--- ADDING TOKEN EMBEDDINGS AND POSITION EMBEDDINGS ---\n",
      "\n",
      "tensor([[[-1.8666, -0.9169,  1.6388, -1.1478],\n",
      "         [ 0.7308, -0.3006,  2.4963, -0.1852],\n",
      "         [ 2.1383, -1.8749,  2.1663, -1.6086]],\n",
      "\n",
      "        [[-0.3667, -0.4216,  1.3401, -2.8618],\n",
      "         [ 2.0366,  0.5538, -0.4894, -0.3094],\n",
      "         [ 0.6384, -2.3702,  2.4649,  0.1055]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# model parameter\n",
    "vocab_size = 5\n",
    "block_size = 7\n",
    "d_model = 4\n",
    "\n",
    "# input parameters\n",
    "sequence_length = 3\n",
    "batch_size = 2\n",
    "\n",
    "# embedding tables\n",
    "token_embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "position_embedding_table = nn.Embedding(block_size, d_model)\n",
    "\n",
    "\n",
    "print(\"--- WEIGHTS OF THE TOKEN EMBEDDING TABLE ---\\n\")\n",
    "print(token_embedding_table.weight) # 5 different tokens, each one is 4-dimensional\n",
    "print(token_embedding_table.weight.shape)\n",
    "\n",
    "\n",
    "print(\"\\n\\n--- WEIGHTS OF THE POSITION EMBEDDING TABLE ---\\n\")\n",
    "print(position_embedding_table.weight) # 7 different positions, each one is 4-dimensional\n",
    "print(position_embedding_table.weight.shape)\n",
    "\n",
    "print(\"\\n\\n--- INPUT INDICES ---\\n\")\n",
    "idx = torch.randint(0, vocab_size, (batch_size, sequence_length)) # 3 random indices between 0 and 4\n",
    "print(idx)\n",
    "print(idx.shape)\n",
    "\n",
    "print(\"\\n\\n--- TOKEN EMBEDDINGS ---\\n\")\n",
    "token_embeddings = token_embedding_table(idx) # 2 sequences of 3 tokens, each one is 4-dimensional\n",
    "print(token_embeddings)\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "print(\"\\n\\n--- POSITION EMBEDDINGS ---\\n\")\n",
    "t = torch.arange(sequence_length) # 3 positions\n",
    "print(t)\n",
    "position_embeddings = position_embedding_table(t) # 3 positions, each one is 4-dimensional\n",
    "print(position_embeddings)\n",
    "print(position_embeddings.shape)\n",
    "\n",
    "print(\"\\n\\n--- ADDING TOKEN EMBEDDINGS AND POSITION EMBEDDINGS ---\\n\")\n",
    "print(token_embeddings + position_embeddings)\n",
    "print((token_embeddings + position_embeddings).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
